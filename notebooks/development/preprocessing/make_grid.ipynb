{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)\n",
    "src_dir = os.environ.get('srcdir')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport features.bathy_smoothing\n",
    "from features.resample_roms import resample\n",
    "from features.bathy_smoothing import smoothing_PlusMinus_rx0,smoothing_PositiveVolume_rx0\n",
    "from features.cartesian_grid_2d import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run = os.environ.get('run')\n",
    "run ='waom10'\n",
    "mr = 10 #km\n",
    "smooth = False\n",
    "deepen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish the grid with grid point distances of mr/2 in km\n",
    "#we need double resolution to cover all of the staggered grid points (we subset to rho, psi, u, v points later)\n",
    "#we need an extra line of u and v points at first to calculate all dx and dy on rho points\n",
    "x,y = np.meshgrid(np.arange(-3000,3300+mr/2,mr/2),np.arange(-2700,2600+mr/2,mr/2))\n",
    "#x,y = np.meshgrid(np.arange(-4300,4300+mr/2,mr/2),np.arange(-3700,3600+mr/2,mr/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load south polar stereographic projection to convert from grid point distance in m to lat/lon and back\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "m = Basemap(projection='spstere',lon_0=0,boundinglat=-50,lat_ts=-71)\n",
    "\n",
    "#get lat/lon coordinates at all grid points by shifting the grid to the lower left corner of the map\n",
    "lon,lat=m(x*1000+m.urcrnrx/2,y*1000+m.urcrnry/2,inverse=True)\n",
    "\n",
    "#calculate curvilinear coordinate distances at rho points\n",
    "dx = haversine(lon[1::2,0:-2:2],lat[1::2,0:-2:2],lon[1::2,2::2],lat[1::2,2::2])\n",
    "dy = haversine(lon[0:-2:2,1::2],lat[0:-2:2,1::2],lon[2::2,1::2],lat[2::2,1::2])\n",
    "\n",
    "#calculate curvilinear coordinate metrices\n",
    "pm = 1.0/dx\n",
    "pn = 1.0/dy\n",
    " \n",
    "dndx = np.empty_like(pm)\n",
    "dmde = np.empty_like(pn)\n",
    "\n",
    "dndx[:,1:-1] = 0.5*(pn[:,2:] - pn[:,:-2])\n",
    "dmde[1:-1,:] = 0.5*(pm[2:,:] - pm[:-2,:])\n",
    "\n",
    "dndx[:,0]  = 2*dndx[:,1]  - dndx[:,2]\n",
    "dndx[:,-1] = 2*dndx[:,-2] - dndx[:,-3]\n",
    "dmde[0,:]  = 2*dmde[1,:]  - dmde[2,:]\n",
    "dmde[-1,:] = 2*dmde[-2,:] - dmde[-3,:]\n",
    "\n",
    "#subset lat and lon at rho, psi, u and v points\n",
    "lon_rho = lon[1::2,1::2]\n",
    "lat_rho = lat[1::2,1::2]\n",
    "\n",
    "lon_psi = lon[2:-1:2,2:-1:2]\n",
    "lat_psi = lat[2:-1:2,2:-1:2]\n",
    "\n",
    "lon_u = lon[1::2,2:-1:2]\n",
    "lat_u = lat[1::2,2:-1:2]\n",
    "\n",
    "lon_v = lon[2:-1:2,1::2]\n",
    "lat_v = lat[2:-1:2,1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load rtopo bed and ice topography and resample to rho points\n",
    "rtopo_path = os.path.join(os.environ.get('extdir'),'rtopo','RTopo-2.0.1_30sec_*_S30.nc')\n",
    "rtopo = xr.open_mfdataset(rtopo_path,data_vars='minimal')#.sel(latdim=np.arange(0,7501,50),londim=np.arange(0,43201,100))\n",
    "\n",
    "rt_lon,rt_lat = np.meshgrid(rtopo.lon.values,rtopo.lat.values)\n",
    "bed_raw = resample(rt_lon,rt_lat,lon_rho,lat_rho,rtopo.bedrock_topography.values)\n",
    "ice_raw = resample(rt_lon,rt_lat,lon_rho,lat_rho,rtopo.ice_base_topography.values)\n",
    "\n",
    "#make a copy of the raw bathymetry\n",
    "bed = bed_raw.copy()\n",
    "ice = ice_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set bed minimum depth to 10 cm\n",
    "bed[bed>-0.1]= -0.1\n",
    "#set ice draft at these places to zero \n",
    "ice[bed>0.1] = 0.0\n",
    "#set ice mountains to zero\n",
    "ice[ice>0]= 0.0\n",
    "\n",
    "#set water column thickness to a small positive value (ROMS don't like when bed = ice draft)\n",
    "wct = (-(bed-ice)).copy()\n",
    "ice[wct==0] = bed[wct==0] + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a land/ocean mask depending on water column thickness\n",
    "#(distance between ice and bed or sea surface and bed)\n",
    "#wct = (-(bed-ice)).copy()\n",
    "mask = np.ones_like(wct)\n",
    "mask[wct<20] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#smooth=True\n",
    "#deepen=True\n",
    "if smooth:\n",
    "    #if smoothing is activated smooth wct and bed and set ice draft as bed + wct\n",
    "    mask = np.ones_like(wct)\n",
    "    mask[wct<=0.1] = 0\n",
    "    dA = 1.0/(pn*pm) \n",
    "    bed = -(smoothing_PositiveVolume_rx0(mask,-bed,0.8,dA))\n",
    "    wct = smoothing_PositiveVolume_rx0(mask,wct,0.8,dA)\n",
    "    ice = bed + wct\n",
    "    \n",
    "    #update the minimum wct points as before\n",
    "    bed[bed>-0.1]= -0.1\n",
    "    ice[bed>0.1] = 0.0\n",
    "    ice[ice>0]= 0.0\n",
    "    wct = (-(bed-ice)).copy()\n",
    "    ice[wct==0] = bed[wct==0] + 0.1\n",
    "    \n",
    "    #update the mask\n",
    "    wct = (-(bed-ice)).copy()\n",
    "    mask = np.ones_like(wct)\n",
    "    mask[wct<20] = 0\n",
    "    \n",
    "#if deepening is activated, deepen the bed to a minimum water column thickness of 50m \n",
    "if deepen:\n",
    "    shallow = (wct<50)&(wct>=20)\n",
    "    bed[shallow] = ice[shallow]-50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set spherical flag to 1, since we're creating a curvilinear spherical grid\n",
    "spherical_da = xr.DataArray(int(1),name='spherical',attrs={'flag_meanings': 'Cartesian spherical',\n",
    " 'flag_values': np.array([0, 1], dtype=int),\n",
    " 'long_name': 'grid type logical switch'})\n",
    "\n",
    "xl = mr*np.size(lat_rho,1)*1000\n",
    "xl_da = xr.DataArray(xl,name='xl',attrs={'long_name': 'basin length in the XI-direction', 'units': 'meter'} )\n",
    "el = mr*np.size(lon_rho,0)*1000\n",
    "el_da = xr.DataArray(el,name='el',attrs={'long_name': 'basin length in the ETA-direction', 'units': 'meter'} )\n",
    "\n",
    "angle = lon_rho/180.0*np.pi\n",
    "angle_da = xr.DataArray(angle,name='angle',dims=['eta_rho','xi_rho'],attrs={'long_name': 'angle between XI-axis and EAST', 'units': 'radians'})\n",
    "\n",
    "pn_da = xr.DataArray(pn,name=\"pn\",dims=['eta_rho','xi_rho'],attrs={'long_name': 'curvilinear coordinate metric in ETA', 'units': 'meter-1'})\n",
    "pm_da = xr.DataArray(pm,name='pm',dims=['eta_rho','xi_rho'],attrs={'long_name': 'curvilinear coordinate metric in XI', 'units': 'meter-1'})\n",
    "\n",
    "dmde_da = xr.DataArray(dmde,name='dmde',dims=['eta_rho','xi_rho'],attrs={'long_name': 'ETA-derivative of inverse metric factor pm', 'units': 'meter'})\n",
    "dndx_da = xr.DataArray(dndx,name='dndx',dims=['eta_rho','xi_rho'],attrs={'long_name': 'XI-derivative of inverse metric factor nm', 'units': 'meter'})\n",
    "\n",
    "f = 2*7.29e-5*np.sin(lat_rho*np.pi/180)\n",
    "f_da = xr.DataArray(f,name='f',dims=['eta_rho','xi_rho'],attrs={'long_name': 'Coriolis parameter at RHO-points', 'units': 'second-1'})\n",
    "\n",
    "h_da = xr.DataArray(-bed,name='h',dims=['eta_rho','xi_rho'],attrs={'long_name': 'model bathymetry at RHO-points', 'units': 'meter'})\n",
    "hraw_da = xr.DataArray(-bed_raw,name='hraw',dims=['eta_rho','xi_rho'],attrs={'long_name': 'Working bathymetry at RHO-points', 'units': 'meter'})\n",
    "\n",
    "zice_da = xr.DataArray(ice,name='zice',dims=['eta_rho','xi_rho'],attrs={'long_name': 'model ice draft at RHO-points', 'units': 'meter'})\n",
    "\n",
    "lon_rho_da = xr.DataArray(lon_rho,name='lon_rho',dims=['eta_rho','xi_rho'],attrs={'long_name': 'longitude of RHO-points',\n",
    " 'standard_name': 'longitude',\n",
    " 'units': 'degree_east'})\n",
    "lat_rho_da = xr.DataArray(lat_rho,name='lat_rho',dims=['eta_rho','xi_rho'],attrs={'long_name': 'latitude of RHO-points',\n",
    " 'standard_name': 'latitude',\n",
    " 'units': 'degree_north'})\n",
    "lon_psi_da = xr.DataArray(lon_psi,name='lon_psi',dims=['eta_psi','xi_psi'],attrs={'long_name': 'longitude of psi-points',\n",
    " 'standard_name': 'longitude',\n",
    " 'units': 'degree_east'})\n",
    "lat_psi_da = xr.DataArray(lat_psi,name='lat_psi',dims=['eta_psi','xi_psi'],attrs={'long_name': 'latitude of psi-points',\n",
    " 'standard_name': 'latitude',\n",
    " 'units': 'degree_north'})\n",
    "lon_u_da = xr.DataArray(lon_u,name='lon_u',dims=['eta_u','xi_u'],attrs={'long_name': 'longitude of u-points',\n",
    " 'standard_name': 'longitude',\n",
    " 'units': 'degree_east'})\n",
    "lat_u_da = xr.DataArray(lat_u,name='lat_u',dims=['eta_u','xi_u'],attrs={'long_name': 'latitude of u-points',\n",
    " 'standard_name': 'latitude',\n",
    " 'units': 'degree_north'})\n",
    "lon_v_da = xr.DataArray(lon_v,name='lon_v',dims=['eta_v','xi_v'],attrs={'long_name': 'longitude of v-points',\n",
    " 'standard_name': 'longitude',\n",
    " 'units': 'degree_east'})\n",
    "lat_v_da = xr.DataArray(lat_v,name='lat_v',dims=['eta_v','xi_v'],attrs={'long_name': 'latitude of v-points',\n",
    " 'standard_name': 'latitude',\n",
    " 'units': 'degree_north'})\n",
    "\n",
    "from features.mask_roms_uvp import uvp_masks\n",
    "\n",
    "mask_rho = mask.copy()\n",
    "mask_u,mask_v,mask_psi = uvp_masks(mask_rho)\n",
    "\n",
    "mask_rho_da = xr.DataArray(mask_rho,name='mask_rho',dims=['eta_rho','xi_rho'],attrs={'flag_meanings': 'land water',\n",
    " 'flag_values': np.array([ 0.,  1.]),\n",
    " 'long_name': 'mask on RHO-points'})\n",
    "mask_psi_da = xr.DataArray(mask_psi,name='mask_psi',dims=['eta_psi','xi_psi'],attrs={'flag_meanings': 'land water',\n",
    " 'flag_values': np.array([ 0.,  1.]),\n",
    " 'long_name': 'mask on psi-points'})\n",
    "mask_u_da = xr.DataArray(mask_u,name='mask_u',dims=['eta_u','xi_u'],attrs={'flag_meanings': 'land water',\n",
    " 'flag_values': np.array([ 0.,  1.]),\n",
    " 'long_name': 'mask on u-points'})\n",
    "mask_v_da = xr.DataArray(mask_v,name='mask_v',dims=['eta_v','xi_v'],attrs={'flag_meanings': 'land water',\n",
    " 'flag_values': np.array([ 0.,  1.]),\n",
    " 'long_name': 'mask on v-points'})\n",
    "\n",
    "grd = xr.Dataset({'spherical':spherical_da,\n",
    "                'xl':xl_da,\n",
    "                'el':el_da,\n",
    "                'angle':angle_da,\n",
    "                'pm':pn_da,\n",
    "                'pn':pn_da,\n",
    "                'dndx':dndx_da,\n",
    "                'dmde':dmde_da,\n",
    "                'f':f_da,\n",
    "                'h':h_da,\n",
    "                'hraw':hraw_da,\n",
    "                'zice':zice_da,\n",
    "                'lon_rho':lon_rho_da,\n",
    "                'lat_rho':lat_rho_da,\n",
    "                'lon_psi':lon_psi_da,\n",
    "                'lat_psi':lat_psi_da,\n",
    "                'lon_u':lon_u_da,\n",
    "                'lat_u':lat_u_da,\n",
    "                'lon_v':lon_v_da,\n",
    "                'lat_v':lat_v_da,\n",
    "                'mask_rho':mask_rho_da,\n",
    "                'mask_psi':mask_psi_da,\n",
    "                'mask_u':mask_u_da,\n",
    "                'mask_v':mask_v_da,},\n",
    "               attrs={'history': 'GRID file using make_grid.py, smoothing='+str(smooth)+\n",
    "                      ', deepening='+str(deepen)+', '+str(datetime.date.today()),\n",
    "                      'type': 'ROMS grid file'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(os.environ.get('intdir'),'waom'+str(mr)+'_grd_raw.nc')\n",
    "#out_path = '~/raijin/short/m68/oxr581/waom10_test/waom10_grd_smooth.nc'\n",
    "grd.to_netcdf(out_path,unlimited_dims='bath')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below just left overs from development"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#include masks psi u v in smoothing and deepening"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_earth = np.empty((rows,columns))\n",
    "y_earth = np.empty((rows,columns))\n",
    "\n",
    "x_earth[:,x_0ind] = 0\n",
    "y_earth[y_0ind,:] = 0\n",
    "\n",
    "for column in np.arange(columns-x_0ind-1):\n",
    "    dx = haversine(lon[:,x_0ind+column],lat[:,x_0ind+column],lon[:,x_0ind+column+1],lat[:,x_0ind+column+1])\n",
    "    x_earth[:,x_0ind+column+1] = x_earth[:,x_0ind+column]+dx\n",
    "    \n",
    "for column in np.arange(x_0ind):    \n",
    "    dx = haversine(lon[:,x_0ind-column],lat[:,x_0ind-column],lon[:,x_0ind-column-1],lat[:,x_0ind-column-1])\n",
    "    x_earth[:,x_0ind-column-1] = x_earth[:,x_0ind-column]-dist\n",
    "    \n",
    "for row in np.arange(rows-y_0ind-1):  \n",
    "    dy = haversine(lon[y_0ind+row,:],lat[y_0ind+row,:],lon[y_0ind+row+1,:],lat[y_0ind+row+1,:])\n",
    "    y_earth[y_0ind+row+1,:] = y_earth[y_0ind+row,:]+dy\n",
    "\n",
    "for row in np.arange(y_0ind):\n",
    "    dy = haversine(lon[y_0ind-row,:],lat[y_0ind-row,:],lon[y_0ind-row-1,:],lat[y_0ind-row-1,:])\n",
    "    y_earth[y_0ind-row-1,:] = y_earth[y_0ind-row,:]-dy\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def calc_angle(lon_u,lat_u,lon_v,lat_v):\n",
    "    \n",
    "    DTOR = np.pi/180\n",
    "    \n",
    "    a1 = lat_u[1:,:] - lat_u[:-1,:]\n",
    "    a2 = lon_u[1:,:] - lon_u[:-1,:]\n",
    "    a2[a2<-180]+=360\n",
    "    a2[a2>180]-=360\n",
    "    \n",
    "    a2 = a2*np.cos(0.5*DTOR*(lat_u[1:,:]+lat_u[:-1,:]))\n",
    "    angle = np.arctan2(a1,a2)\n",
    "    \n",
    "    a1 = lat_v[:,:-1] - lat_v[:,1:]\n",
    "    a2 = lon_v[:,:-1] - lon_v[:,1:]\n",
    "    a2[a2<-180]+=360\n",
    "    a2[a2>180]-=360\n",
    "    \n",
    "    a2 = a2*np.cos(0.5*DTOR*(lat_v[:,:-1] + lat_v[:,1:]))\n",
    "    angle = 0.5*(angle + np.arctan2(a2,-a1))    \n",
    "    \n",
    "    return angle\n",
    "\n",
    "angle = calc_angle(lon_u,lat_u,lon_v,lat_v)\n",
    "\n",
    "print(np.shape(angle))\n",
    "plt.close()\n",
    "plt.contour(angle)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_rho_da = xr.DataArray(x_rho*1000,name='x_rho',dims=['eta_rho','xi_rho'],attrs={'long_name': 'X-location of RHO-points', 'units': 'meter'})\n",
    "y_rho_da = xr.DataArray(y_rho*1000,name='y_rho',dims=['eta_rho','xi_rho'],attrs={'long_name': 'Y-location of RHO-points', 'units': 'meter'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_psi_da = xr.DataArray(x_psi*1000,name='x_psi',dims=['eta_rho','xi_rho'],attrs={'long_name': 'X-location of PSI-points', 'units': 'meter'})\n",
    "y_psi_da = xr.DataArray(y_psi*1000,name='y_psi',dims=['eta_psi','xi_psi'],attrs={'long_name': 'Y-location of PSI-points', 'units': 'meter'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_u_da = xr.DataArray(x_u*1000,name='x_u',dims=['eta_u','xi_u'],attrs={'long_name': 'X-location of U-points', 'units': 'meter'})\n",
    "y_u_da = xr.DataArray(y_u*1000,name='y_u',dims=['eta_u','xi_u'],attrs={'long_name': 'Y-location of U-points', 'units': 'meter'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_v_da = xr.DataArray(x_v*1000,name='x_v',dims=['eta_v','xi_v'],attrs={'long_name': 'X-location of V-points', 'units': 'meter'})\n",
    "y_v_da = xr.DataArray(y_v*1000,name='y_v',dims=['eta_v','xi_v'],attrs={'long_name': 'Y-location of V-points', 'units': 'meter'})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib notebook\n",
    "#set up mask_rho depending on water column thickness\n",
    "wct = (bed+ice).copy()\n",
    "mask_rho = np.ones_like(wct)\n",
    "mask_rho[wct<20] = 0\n",
    "\n",
    "def make_neibhour_mask(mask):\n",
    "    neib_xi = np.empty_like(mask)\n",
    "    neib_eta = np.empty_like(mask)\n",
    "\n",
    "    neib_xi[:,1:-1] = mask[:,2:]+mask[:,:-2]\n",
    "    neib_xi[:,0] = neib_xi[:,1]\n",
    "    neib_xi[:,-1] = neib_xi[:,-2]\n",
    "\n",
    "    neib_eta[1:-1,:] = mask[2:,:]+mask[:-2,:]\n",
    "    neib_eta[0,:] = neib_eta[1,:]\n",
    "    neib_eta[-1,:] = neib_eta[-2,:]\n",
    "\n",
    "    return neib_eta + neib_xi"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#first get rid of any dubious ocean point nort of 60S\n",
    "mask_sa = mask_rho.copy()\n",
    "mask_sa[(lat_rho>-60)&(neib<=1)] = 0\n",
    "\n",
    "#neib = make_neibhour_mask(mask_sa)\n",
    "#mask_sa[(lat_rho>-60)&(neib<=3)] = 0\n",
    "\n",
    "plt.close()\n",
    "plt.pcolormesh(mask_sa)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "intdirintdirplt.close()\n",
    "plt.pcolormesh(neib)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#then, more carefully, find and mask ocean point around antarctica that are sorounded by land\n",
    "Nmodif=1\n",
    "while Nmodif > 0:\n",
    "    mask_new = mask_tmp.copy()\n",
    "    neib = make_neibhour_mask(mask_tmp)\n",
    "    mask_new[(lat_rho<=-60)&(neib<=1)] = 0\n",
    "    Nmodif = np.sum(mask_tmp)-np.sum(mask_new)\n",
    "    print(Nmodif)\n",
    "    mask_tmp = mask_new.copy()\n",
    "\n",
    "mask_tmp[(lat_rho<=-60)&(neib<=2)] =0\n",
    "\n",
    "Nmodif=1\n",
    "while Nmodif > 0:\n",
    "    mask_new = mask_tmp.copy()\n",
    "    neib = make_neibhour_mask(mask_tmp)\n",
    "    mask_new[(lat_rho<=-60)&(neib<=1)] = 0\n",
    "    Nmodif = np.sum(mask_tmp)-np.sum(mask_new)\n",
    "    print(Nmodif)\n",
    "    mask_tmp = mask_new.copy()\n",
    "plt.close()\n",
    "plt.pcolormesh(mask_rho)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#include the amundsen fix from Milan 2017\n",
    "\n",
    "#first load and resample to whole roms rho grid\n",
    "import scipy.io as sio\n",
    "amundsen_fix_path = os.path.join(os.environ.get('extdir'),'rtopo','Bathymetry_ASE_Millan_et_al_2017.nc')\n",
    "amu_fix = xr.open_dataset(amundsen_fix_path)\n",
    "amundsen_fix_latlon_path = os.path.join(os.environ.get('extdir'),'rtopo','lon_lat_romain_grid.mat')\n",
    "amu_fix_latlon = sio.loadmat(amundsen_fix_latlon_path)\n",
    "\n",
    "amu_lon = amu_fix_latlon['lone']\n",
    "amu_lat = amu_fix_latlon['late']\n",
    "amu_lon[amu_lon>180]-=360.0\n",
    "amu = resample(amu_lon,amu_lat,lon_rho,lat_rho,amu_fix.BED.values)\n",
    "\n",
    "#then lookup indices of coorner coordinates and subset the working bathymetry just there \n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "points = np.column_stack((lon_rho.flatten(),lat_rho.flatten()))\n",
    "\n",
    "tree = KDTree(points)\n",
    "\n",
    "target = np.column_stack((amu_lon[0,0],amu_lat[0,0]))\n",
    "llcDist, llcInd = tree.query(target)\n",
    "llcInd = np.squeeze(llcInd)\n",
    "\n",
    "target = np.column_stack((amu_lon[-1,-1],amu_lat[-1,-1]))\n",
    "urcDist, urcInd = tree.query(target)\n",
    "urcInd = np.squeeze(urcInd)\n",
    "\n",
    "#establish grid coordinates at rho points only (needed for the amundsen fix)\n",
    "xi_rho = np.arange((np.size(x,1)-1)/2,dtype=int)\n",
    "eta_rho = np.arange((np.size(x,0)-1)/2,dtype=int)\n",
    "\n",
    "xi_2d,eta_2d = np.meshgrid(xi_rho,eta_rho)\n",
    "xiEta = np.column_stack((xi_2d.flatten(),eta_2d.flatten()))\n",
    "\n",
    "xi_amu_ll,xi_amu_ur = xiEta[llcInd][0],xiEta[urcInd][0]\n",
    "eta_amu_ll,eta_amu_ur = xiEta[llcInd][1],xiEta[urcInd][1]\n",
    "\n",
    "bed[eta_amu_ll:eta_amu_ur+1,xi_amu_ll:xi_amu_ur+1] = amu[eta_amu_ll:eta_amu_ur+1,xi_amu_ll:xi_amu_ur+1]\n",
    "bed=bed*-1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#have a look at the amundsen patch\n",
    "plt.close()\n",
    "plt.pcolormesh(bed[eta_amu_ll-20:eta_amu_ur+21,xi_amu_ll-20:xi_amu_ur+21])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

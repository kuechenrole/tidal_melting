{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)\n",
    "src_dir = os.environ.get('srcdir')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport features.resample\n",
    "from features.resample import resample\n",
    "from features.grid_ttide import NDinterp\n",
    "from features.log_progress import log_progress\n",
    "\n",
    "run = os.environ.get('run')\n",
    "#run ='waom10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in tamura land mask\n",
    "T_mask_path = os.path.join(os.environ.get('extdir'),'tamura','EASE_landmask_H.data')\n",
    "with open(T_mask_path,'rb') as fid:\n",
    "    T_mask = np.fromfile(fid,count=(721*721),dtype='float32').reshape((721,721))\n",
    "    T_mask = np.flipud(T_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tamura lat lon coordinates\n",
    "T_lat_lon_path = os.path.join(os.environ.get('extdir'),'tamura','latlon.data')\n",
    "with open(T_lat_lon_path,'rb') as fid:\n",
    "    T_lat_lon = np.fromfile(fid,count=(721*721*2),dtype='float32').reshape((2,721,721))\n",
    "T_lat,T_lon = (T_lat_lon[0],T_lat_lon[1])\n",
    "T_lat = np.flipud(T_lat)\n",
    "T_lon = np.flipud(T_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/bigStick/anaconda3/envs/tidal_melting/lib/python3.6/site-packages/xarray/core/common.py:594: FutureWarning: pd.TimeGrouper is deprecated and will be removed; Please use pd.Grouper(freq=...)\n",
      "  label=label, base=base)\n"
     ]
    }
   ],
   "source": [
    "#read in era interim winds and resample from twice daily to daily\n",
    "era_path = os.path.join(os.environ.get('extdir'),'era_interim','ERA_Interim_1992_2011.2daily.*winds.nc')\n",
    "era_ds = xr.open_mfdataset(era_path,data_vars='minimal').sel(time='2007',latitude=slice(-30,-90)).resample(time='D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get era coordinates\n",
    "era_lat = era_ds.latitude.values\n",
    "era_lon = era_ds.longitude.values\n",
    "era_lon[era_lon>180]-=360.0\n",
    "E_lon,E_lat = np.meshgrid(era_lon,era_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get roms grid\n",
    "R_grid_path = os.path.join(os.environ.get('prodir'),run+'_grd.nc')\n",
    "R_grid = xr.open_dataset(R_grid_path)\n",
    "R_lon = R_grid.lon_rho.values\n",
    "R_lat = R_grid.lat_rho.values\n",
    "R_angle = R_grid.angle.values\n",
    "R_ulon = R_grid.lon_u.values\n",
    "R_vlon = R_grid.lon_v.values\n",
    "R_ulat = R_grid.lat_u.values\n",
    "R_vlat = R_grid.lat_v.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing month:  jan with days:  1\n",
      "Containing days of year:  [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84814fd9462406bbe05b8c1e3d80780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=1)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving month to /home/ubuntu/bigStick/tidal_melting/data/preprocessing/interim/waom10_sbc_jan.nc\n",
      "Processing month:  feb with days:  2\n",
      "Containing days of year:  [2 3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceeb1f1148547438eaf374a862dffbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=2)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving month to /home/ubuntu/bigStick/tidal_melting/data/preprocessing/interim/waom10_sbc_feb.nc\n"
     ]
    }
   ],
   "source": [
    "month = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "daysPerMonth = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "month = ['jan','feb']\n",
    "daysPerMonth = [1,2]\n",
    "dayOfYear = 1\n",
    "\n",
    "for month,days in zip(month,daysPerMonth):\n",
    "    \n",
    "    print('Processing month: ',month,'with days: ',days)\n",
    "    \n",
    "    daysOfYear = np.arange(dayOfYear,dayOfYear+days,dtype=int)\n",
    "    \n",
    "    print('Containing days of year: ',daysOfYear)\n",
    "\n",
    "    # preparing empty dataset\n",
    "    ds = xr.Dataset({'shflux':(['shf_time','eta_rho','xi_rho'], np.empty((days,R_grid.eta_rho.size,R_grid.xi_rho.size))),\n",
    "                     'swflux':(['swf_time','eta_rho','xi_rho'], np.empty((days,R_grid.eta_rho.size,R_grid.xi_rho.size))),\n",
    "                     'sustr':(['sms_time','eta_u','xi_u'], np.empty((days,R_grid.eta_u.size,R_grid.xi_u.size))),\n",
    "                     'svstr':(['sms_time','eta_v','xi_v'], np.empty((days,R_grid.eta_v.size,R_grid.xi_v.size)))},\n",
    "                   coords={'shf_time':(['shf_time'],daysOfYear),\n",
    "                           'swf_time':(['swf_time'],daysOfYear),\n",
    "                           'sms_time':(['sms_time'],daysOfYear)})\n",
    "   \n",
    "    #open Tamura month flux data \n",
    "    T_data_path = os.path.join(os.environ.get('extdir'),'tamura','TSDM2hb_2007_'+month+'.data')\n",
    "    with open(T_data_path,'rb') as fid:\n",
    "        T_data = np.swapaxes(np.fromfile(fid,count = days*6*721*721 ,dtype='float32').reshape(days,6,721,721),0,1)\n",
    "    \n",
    "    #looping over the days with running day-of-the-year and day-of-the-month index\n",
    "    for Eidx,Tidx in zip(log_progress(daysOfYear-1,name='days'),np.arange(days)):\n",
    "        \n",
    "        #read in Tamura heat and fresh water flux and turn in right position\n",
    "        shflux_tmp = np.flipud(T_data[0,Tidx])\n",
    "        ssflux_tmp = np.flipud(T_data[2,Tidx])\n",
    "        \n",
    "        #fill in tamuar mask for later resampling\n",
    "        shflux_tmp[T_mask==0] = np.nan\n",
    "        shflux_tmp = NDinterp(shflux_tmp)\n",
    "        \n",
    "        ssflux_tmp[T_mask==0] = np.nan\n",
    "        ssflux_tmp = NDinterp(ssflux_tmp)\n",
    "\n",
    "        #resample to roms grid points\n",
    "        shflux_tmp = resample(T_lon,T_lat,R_lon,R_lat,shflux_tmp)\n",
    "        ssflux_tmp = resample(T_lon,T_lat,R_lon,R_lat,ssflux_tmp)\n",
    "        \n",
    "        #correct large summer heat flux values and save to dataset\n",
    "        shflux_tmp[shflux_tmp > 0.0]*=0.5\n",
    "        \n",
    "        ds.shflux[Tidx] = shflux_tmp\n",
    "        \n",
    "        #convert to freshwater flux with convention positive up 'swf (E-P)',\n",
    "        #that means a positive freshwater flux value results in positive salt flux value\n",
    "        #and save to dataset\n",
    "        refSalt = 34.4\n",
    "\n",
    "        ds.swflux[Tidx] = ssflux_tmp/refSalt*100\n",
    "        \n",
    "        #resample era-interim winds to roms grid\n",
    "        uwnd = resample(E_lon,E_lat,R_lon,R_lat,era_ds.u10[Eidx].values)\n",
    "        vwnd = resample(E_lon,E_lat,R_lon,R_lat,era_ds.v10[Eidx].values)\n",
    "        \n",
    "        #rotate wind directions to roms grid\n",
    "        uv = (uwnd+1j*vwnd)*np.exp(1j*-R_angle)\n",
    "        uwnd = uv.real\n",
    "        vwnd = uv.imag\n",
    "        \n",
    "        #convert to stress\n",
    "        signu = np.sign(uwnd)\n",
    "        signv = np.sign(vwnd)\n",
    "\n",
    "        rhoAir = 1.3\n",
    "        Cd = 1.4e-3\n",
    "\n",
    "        taux = rhoAir*Cd*np.square(uwnd)*signu\n",
    "        tauy = rhoAir*Cd*np.square(vwnd)*signv\n",
    "        \n",
    "        #resample to roms u and v grid and save to dataset\n",
    "        taux = resample(R_lon,R_lat,R_ulon,R_ulat,taux)\n",
    "        tauy = resample(R_lon,R_lat,R_vlon,R_vlat,tauy)\n",
    "        \n",
    "        ds.sustr[Tidx]=taux\n",
    "        ds.svstr[Tidx]=tauy\n",
    "        \n",
    "    #add attributes to data set and data arrays\n",
    "    ds.attrs={'title':'waom surface heat/fresh water fluxes and wind stress',\n",
    "                          'date':str(datetime.date.today()),\n",
    "                          'tamura_file':T_data_path,\n",
    "                          'era-interim file':era_path,\n",
    "                          'grid file':R_grid_path,\n",
    "                          'type':'ROMS forcing file'}\n",
    "    ds.shflux.attrs = {'long_name': 'surface net heat flux', 'units': 'Watts meter-2'}\n",
    "    ds.swflux.attrs = {'long_name': 'surface freshwater flux (E-P)',\n",
    "                       'negative': 'net precipitation',\n",
    "                       'positive': 'net evaporation',\n",
    "                       'units': 'centimetre day-1'}\n",
    "    ds.sustr.attrs = {'long_name': 'surface u-momentum stress', 'units': 'Newton meter-2'}\n",
    "    ds.svstr.attrs = {'long_name': 'surface u-momentum stress', 'units': 'Newton meter-2'}\n",
    "    ds.sms_time.attrs = {'cycle_length': days,'long_name': 'surface momentum stress time','units': 'day'}\n",
    "    ds.shf_time.attrs = {'cycle_length': days, 'long_name': 'surface heat flux time', 'units': 'day'}\n",
    "    ds.swf_time.attrs = {'cycle_length': days,'long_name': 'surface freshwater flux time','units': 'day'}\n",
    "    \n",
    "    #save month as netcdf file\n",
    "    out_path = os.path.join(os.environ.get('intdir'),run+'_sbc_'+month+'.nc') \n",
    "    print(\"Saving month to \"+out_path)\n",
    "    ds.to_netcdf(out_path,'w')\n",
    "    \n",
    "    #update the day of the year value for next month\n",
    "    dayOfYear += days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: /home/ubuntu/bigStick/tidal_melting/data/preprocessing/interim/waom10_sbc_jan.nc\n",
      "loading: /home/ubuntu/bigStick/tidal_melting/data/preprocessing/interim/waom10_sbc_2007.nc\n",
      "loading: /home/ubuntu/bigStick/tidal_melting/data/preprocessing/interim/waom10_sbc_feb.nc\n",
      "and saving to /home/ubuntu/bigStick/tidal_melting/data/preprocessing/processed/waom10_sbc_2007.nc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import glob\n",
    "\n",
    "run_name = os.environ.get('run')\n",
    "\n",
    "\n",
    "# concatenate all monthly data into a single file\n",
    "monthly_data_paths = os.path.join(os.environ.get('intdir'),run+'_sbc_*.nc')\n",
    "for file in glob.glob(monthly_data_paths):\n",
    "    print('loading: '+file)\n",
    "\n",
    "ds = xr.open_mfdataset(monthly_data_paths,concat_dim=None)\n",
    "ds = ds.chunk(chunks={'shf_time':3,'swf_time':3,'sms_time':3})\n",
    "for time in ['shf_time','swf_time','sms_time']:\n",
    "    ds[time]['cycle_length'] = ds[time].cycle_length.size\n",
    "year_data_path = os.path.join(os.environ.get('prodir'),run+'_sbc_2007.nc')\n",
    "\n",
    "print('and saving to '+year_data_path)\n",
    "ds.to_netcdf(year_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total kinetic energy, total ocean heat content and average salinity\n",
    "## Preprocessing\n",
    "Load data, get cartesian coordinates, calculate time dependent volumes of cells and interpolate velocities onto rho grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.environ.get('projdir'),'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my methods, make sure they get reloded by each call\n",
    "from features.roms_ds import make_cartesian_grid_3D, make_uv_lonlat, make_4D_depth\n",
    "%aimport features.roms_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file:  /home/ubuntu/bigStick/tidal_melting/data/analysis/raw/waom10_full_forcing/ocean_avg_000[1,2].nc\n",
      "calculate dx,dy,dz and dV\n",
      "interpolate velocities on rho points\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(os.environ.get('projdir'),'data','analysis','raw','waom10_full_forcing','ocean_avg_000[1,2].nc')\n",
    "print('Load file: ',file_path)\n",
    "ds = xr.open_mfdataset(file_path,data_vars=\"minimal\")\n",
    "print('calculate dx,dy,dz and dV')\n",
    "ds = make_cartesian_grid_3D(ds)\n",
    "print('interpolate velocities on rho points')\n",
    "ds = make_uv_lonlat(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 4D arrays of ocean heat content and kinetic energy.\n",
    "**** CAUTION you need to write out density anomaly rho and use rho=rho0 instead of rho! ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating ocean heat content of each cell at all times\n"
     ]
    }
   ],
   "source": [
    "rho0 = 1027.0    # Reference density (kg/m^3)\n",
    "Cp = 3974        # Specific heat of polar seawater (J/K/kg)\n",
    "C2K = 273.15     # Celsius to Kelvin conversion\n",
    "\n",
    "#rho = ds.rho+ds.rho0\n",
    "rho=rho0\n",
    "print('calculating ocean heat content of each cell at all times')\n",
    "ohc = (ds.temp+C2K)*rho*Cp*ds.dV\n",
    "\n",
    "ds['ohc'] = xr.DataArray(ohc,dims=['ocean_time','s_rho','eta_rho','xi_rho'])\n",
    "ds['ohc'] = ds.ohc.where(ds.mask_rho == 1)\n",
    "ds.ohc.attrs = {\"long_name\":'Heat content',\"units\": 'J'}\n",
    "\n",
    "print('calculating kinetic energy of each cell at all times')\n",
    "ke = 0.5*rho*(ds.u_lonlat**2 + ds.v_lonlat**2)*ds.dV\n",
    "\n",
    "ds['kine'] = xr.DataArray(ke,dims=['ocean_time','s_rho','eta_rho','xi_rho'])\n",
    "ds['kine'] = ds.kine.where(ds.mask_rho == 1)\n",
    "ds.kine.attrs = {\"long_name\":'kinetic energy',\"units\": 'J'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole domain evolution\n",
    "We start calculating and plotting the integrated/mean values of the wohle domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tohc = ds.ohc.sum(dim=['s_rho','xi_rho','eta_rho'])\n",
    "tke = ds.kine.sum(dim=['s_rho','xi_rho','eta_rho'])\n",
    "weights = ds.dV*rho/(ds.dV*rho).sum(dim=['s_rho','xi_rho','eta_rho'])\n",
    "avg_salt = (ds.salt * weights).sum(dim=['s_rho','xi_rho','eta_rho'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig,(ax1,ax2,ax3)=plt.subplots(3,figsize=(15,7))\n",
    "tohc.plot(ax=ax1)\n",
    "tke.plot(ax=ax2)\n",
    "avg_salt.plot(ax=ax3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  On shelf ocean\n",
    "By selecting data above 1000m, south of 60S and under the cavity, I separate the for us interesting on shelf and slower spin up off shelf ocean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = make_4D_depth(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig,(ax1,ax2,ax3)=plt.subplots(3,figsize=(15,7))\n",
    "ds.ohc.where((ds.lat_rho<=-60) & ((ds.zice<0.0) | (ds.depth>-1000))).sum(dim=['s_rho','xi_rho','eta_rho']).plot(ax=ax1)\n",
    "ds.kine.where((ds.lat_rho<=-60) & ((ds.zice<0.0) | (ds.depth>-1000))).sum(dim=['s_rho','xi_rho','eta_rho']).plot(ax=ax2)\n",
    "weights = ds.dV.where((ds.lat_rho<=-60) & ((ds.zice<0.0) | (ds.depth>-1000)))*rho/(ds.dV.where((ds.lat_rho<=-60) & ((ds.zice<0.0) | (ds.depth>-1000)))*rho).sum(dim=['s_rho','xi_rho','eta_rho'])\n",
    "(ds.salt * weights).where((ds.lat_rho<=-60) & ((ds.zice<0.0) | (ds.depth>-1000))).sum(dim=['s_rho','xi_rho','eta_rho']).plot(ax=ax3)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
